{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_text_test_embeddings = pd.read_csv('final_test_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_identifiers = df_text_test_embeddings[['imageid', 'productid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 84916 entries, 0 to 84915\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   designation  84916 non-null  object\n",
      " 1   description  55116 non-null  object\n",
      " 2   productid    84916 non-null  int64 \n",
      " 3   imageid      84916 non-null  int64 \n",
      " 4   prdtypecode  84916 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Chargement des fichiers \"X_train_uptade.csv\" et \"Y_trainCVw08PX.csv\"\n",
    "df_1 = pd.read_csv('../../X_train.csv', index_col=0)\n",
    "df_2 = pd.read_csv('../../y_train.csv', index_col=0)\n",
    "\n",
    "# Fusion avec merge des deux datasets\n",
    "df_classes = pd.merge(df_1, df_2, left_index = True, right_index = True)\n",
    "\n",
    "df_classes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classes = df_classes[['imageid', 'productid', 'prdtypecode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création de Nom Image et lien\n",
    "df_classes['Nom image'] = ['image_' + str(imageid) + '_product_' + str(productid) + '.jpg' for imageid, productid in zip(df_classes['imageid'], df_classes['productid'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './datasets/images_train_upscalled'\n",
    "df_classes['lien'] = str(path) + '/' + df_classes['prdtypecode'].astype(str)+ '/' + df_classes['Nom image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner df_classes avec df_test_identifiers en utilisant la colonne 'imageid' pour récupérer 'prdtypecode'\n",
    "df_classes_test = df_classes.merge(df_test_identifiers['imageid'], on='imageid', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16984 entries, 0 to 16983\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   imageid      16984 non-null  int64 \n",
      " 1   productid    16984 non-null  int64 \n",
      " 2   prdtypecode  16984 non-null  int64 \n",
      " 3   Nom image    16984 non-null  object\n",
      " 4   lien         16984 non-null  object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 663.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_classes_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout du mapping des classes pour les images\n",
    "classe_images = pd.read_csv('class_images_mapping.csv')\n",
    "classe_images.rename(columns={'Class Name': 'prdtypecode', 'label': 'class_image'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prdtypecode</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1160</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1180</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1281</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1300</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1301</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1302</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1320</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1560</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1920</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1940</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2060</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2220</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2280</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2403</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2462</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2522</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2582</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2583</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2585</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2705</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2905</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prdtypecode  Label\n",
       "0            10      0\n",
       "1          1140      1\n",
       "2          1160      2\n",
       "3          1180      3\n",
       "4          1280      4\n",
       "5          1281      5\n",
       "6          1300      6\n",
       "7          1301      7\n",
       "8          1302      8\n",
       "9          1320      9\n",
       "10         1560     10\n",
       "11         1920     11\n",
       "12         1940     12\n",
       "13         2060     13\n",
       "14         2220     14\n",
       "15         2280     15\n",
       "16         2403     16\n",
       "17         2462     17\n",
       "18         2522     18\n",
       "19         2582     19\n",
       "20         2583     20\n",
       "21         2585     21\n",
       "22         2705     22\n",
       "23         2905     23\n",
       "24           40     24\n",
       "25           50     25\n",
       "26           60     26"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classe_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation des dossiers et des images pour le test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(si déjà fait pas besoin de re-run la première cellule de code ci-dessous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# On ajuste le dossier au path du nouveau lien pour les données de test\n",
    "df_classes_test['lien_test'] = df_classes_test['lien'].str.replace('images_train_upscalled', 'images_test_upscalled')\n",
    "\n",
    "# On créer les dossiers et fichiers pour le test (si déjà fait pas besoin de re-run ce code)\n",
    "def copy_images(row):\n",
    "    os.makedirs(os.path.dirname(row['lien_test']), exist_ok=True)\n",
    "    shutil.copy(row['lien'], row['lien_test'])\n",
    "\n",
    "# on applique la fonction pour chaque ligne du dataframe\n",
    "df_classes_test.apply(copy_images, axis=1)\n",
    "#df_classes_test.to_csv(\"./final_image_test_dataset.csv\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTForImageClassification, ViTConfig\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# load du model\n",
    "def load_model(filepath, device='cpu'):\n",
    "    device = torch.device(device)\n",
    "    config = ViTConfig.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=27, output_hidden_states=True)\n",
    "    model = ViTForImageClassification(config)\n",
    "    try:\n",
    "        checkpoint = torch.load(filepath, map_location=device)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "    except KeyError:\n",
    "        model.load_state_dict(torch.load(filepath, map_location=device))\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "model = load_model(\"final_model_image.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./datasets/images_test_upscalled\"\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "test_dataset = datasets.ImageFolder(dataset_path, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) # shuffle false consèrve l'ordre des images, peut être aurions nous dû utiliser shuffle true pour un mélange aléatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function pour récupérer les embeddings avec les predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16984 entries, 0 to 16983\n",
      "Columns: 770 entries, 0 to productid\n",
      "dtypes: float32(768), object(2)\n",
      "memory usage: 50.0+ MB\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings_and_predictions(model, dataloader):\n",
    "    model.eval()\n",
    "    embeddings, predictions, paths = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            embeddings.extend(outputs.hidden_states[-1][:, 0, :].cpu().numpy())  # Extraction des embeddings \n",
    "            _, preds = torch.max(outputs.logits, 1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            start_index = batch_idx * dataloader.batch_size\n",
    "            # récupération des chemins de chaque image (pour les utiliser comme identifiers)\n",
    "            batch_paths = [dataloader.dataset.samples[i][0] for i in range(start_index, start_index + len(labels))]\n",
    "            paths.extend(batch_paths)\n",
    "    return embeddings, predictions, paths\n",
    "\n",
    "embeddings, predictions, paths = get_embeddings_and_predictions(model, test_loader)\n",
    "\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "#embeddings_df['predictions'] = predictions\n",
    "embeddings_df['path'] = paths\n",
    "embeddings_df['Nom image'] = embeddings_df['path'].str.extract(r'.*\\\\(image_.*)')\n",
    "# Split the 'Nom image' column to extract 'imageid' and 'productid'\n",
    "split_columns = embeddings_df['Nom image'].str.split('_', expand=True)\n",
    "\n",
    "# Create 'imageid' and 'productid' columns in embeddings_df\n",
    "embeddings_df['imageid'] = split_columns[1]\n",
    "embeddings_df['productid'] = split_columns[3].str.replace('.jpg', '')\n",
    "\n",
    "embeddings_df.drop(columns=['path', 'Nom image'], inplace=True)\n",
    "embeddings_df.info()\n",
    "embeddings_df.to_csv(\"final_image_test_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut préparer le même dataset d'embeddings pour les données d'entrainement. Mais pour celà il faut déjà préparer les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 84916 entries, 0 to 84915\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   imageid      84916 non-null  int64 \n",
      " 1   productid    84916 non-null  int64 \n",
      " 2   prdtypecode  84916 non-null  int64 \n",
      " 3   Nom image    84916 non-null  object\n",
      " 4   lien         84916 non-null  object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_classes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16984 entries, 0 to 16983\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   imageid      16984 non-null  int64 \n",
      " 1   productid    16984 non-null  int64 \n",
      " 2   prdtypecode  16984 non-null  int64 \n",
      " 3   Nom image    16984 non-null  object\n",
      " 4   lien         16984 non-null  object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 663.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_classes_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fusion de df_classes et df_classes_test en utilisant 'imageid' \n",
    "merged_df = df_classes.merge(df_classes_test[['imageid']], on='imageid', how='left', indicator=True)\n",
    "\n",
    "# Filtrer pour trouver les lignes en commun\n",
    "result_df = merged_df[merged_df['_merge'] == 'left_only']\n",
    "result_df = result_df.drop(columns=['_merge'])\n",
    "df_exclusive_classes = result_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 67932 entries, 0 to 84914\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   imageid      67932 non-null  int64 \n",
      " 1   productid    67932 non-null  int64 \n",
      " 2   prdtypecode  67932 non-null  int64 \n",
      " 3   Nom image    67932 non-null  object\n",
      " 4   lien         67932 non-null  object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_exclusive_classes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(si déjà fait pas besoin de re-run la première cellule de code ci-dessous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# On ajuste le dossier au path du nouveau lien pour les données de test\n",
    "df_exclusive_classes['lien_train_final'] = df_exclusive_classes['lien'].str.replace('images_train_upscalled', 'images_train_upscalled_final')\n",
    "\n",
    "# On créer les dossiers et fichiers pour le test (si déjà fait pas besoin de re-run ce code)\n",
    "def copy_images(row):\n",
    "    os.makedirs(os.path.dirname(row['lien_train_final']), exist_ok=True)\n",
    "    shutil.copy(row['lien'], row['lien_train_final'])\n",
    "\n",
    "# on applique la fonction pour chaque ligne du dataframe\n",
    "df_exclusive_classes.apply(copy_images, axis=1)\n",
    "df_exclusive_classes.to_csv(\"./final_image_train_dataset.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 67932 entries, 0 to 84914\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   imageid           67932 non-null  int64 \n",
      " 1   productid         67932 non-null  int64 \n",
      " 2   prdtypecode       67932 non-null  int64 \n",
      " 3   Nom image         67932 non-null  object\n",
      " 4   lien              67932 non-null  object\n",
      " 5   lien_train_final  67932 non-null  object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_exclusive_classes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./datasets/images_train_upscalled_final\"\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "test_dataset = datasets.ImageFolder(dataset_path, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     imageid   productid  prdtypecode  \\\n",
      "0           0  1263597046  3804725264           10   \n",
      "1           1  1008141237   436067568         2280   \n",
      "2           2   938777978   201115110           50   \n",
      "3           3   457047496    50418756         1280   \n",
      "4           4  1077757786   278535884         2705   \n",
      "\n",
      "                                 Nom image  \\\n",
      "0  image_1263597046_product_3804725264.jpg   \n",
      "1   image_1008141237_product_436067568.jpg   \n",
      "2    image_938777978_product_201115110.jpg   \n",
      "3     image_457047496_product_50418756.jpg   \n",
      "4   image_1077757786_product_278535884.jpg   \n",
      "\n",
      "                                                lien  \\\n",
      "0  ./datasets/images_train_upscalled/10/image_126...   \n",
      "1  ./datasets/images_train_upscalled/2280/image_1...   \n",
      "2  ./datasets/images_train_upscalled/50/image_938...   \n",
      "3  ./datasets/images_train_upscalled/1280/image_4...   \n",
      "4  ./datasets/images_train_upscalled/2705/image_1...   \n",
      "\n",
      "                                    lien_train_final  \n",
      "0  ./datasets/images_train_upscalled_final/10/ima...  \n",
      "1  ./datasets/images_train_upscalled_final/2280/i...  \n",
      "2  ./datasets/images_train_upscalled_final/50/ima...  \n",
      "3  ./datasets/images_train_upscalled_final/1280/i...  \n",
      "4  ./datasets/images_train_upscalled_final/2705/i...  \n"
     ]
    }
   ],
   "source": [
    "# Si on reprend le code ici et on a besoin de charger df_exclusive_classes\n",
    "import pandas as pd\n",
    "df_exclusive_classes = pd.read_csv(\"./final_image_train_dataset.csv\")\n",
    "print(df_exclusive_classes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelques ajustements à get_embeddings_and_predictions pour pallier à des problèmes de mémoires lorsque l'on travaille sur le dataset d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_embeddings_and_predictions_generator(model, dataloader):\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "            images = images.to(device)  # selection du device approprié\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Extraction de l'embeddings\n",
    "            embeddings = outputs.hidden_states[-1][:, 0, :].cpu().numpy()\n",
    "            _, preds = torch.max(outputs.logits, 1)\n",
    "            predictions = preds.cpu().numpy()\n",
    "            \n",
    "            # récupération des chemins de chaque image (pour les utiliser comme identifiers)\n",
    "            start_index = batch_idx * dataloader.batch_size\n",
    "            batch_paths = [dataloader.dataset.samples[i][0] for i in range(start_index, start_index + len(labels))]\n",
    "            \n",
    "            yield embeddings, predictions, batch_paths  # On utilise Yield\n",
    "\n",
    "for embeddings, predictions, paths in get_embeddings_and_predictions_generator(model, test_loader):\n",
    "    # process immédiatement chaque batch\n",
    "    embeddings_df_batch = pd.DataFrame(embeddings)\n",
    "    #embeddings_df_batch['predictions'] = predictions\n",
    "    embeddings_df_batch['path'] = paths\n",
    "    embeddings_df_batch['Nom image'] = embeddings_df_batch['path'].str.extract(r'.*\\\\(image_.*)')\n",
    "\n",
    "    # Division de la colonne 'Nom image' pour extraire 'imageid' et 'productid'\n",
    "    split_columns = embeddings_df_batch['Nom image'].str.split('_', expand=True)\n",
    "    embeddings_df_batch['imageid'] = split_columns[1]\n",
    "    embeddings_df_batch['productid'] = split_columns[3].str.replace('.jpg', '')\n",
    "\n",
    "    embeddings_df_batch.drop(columns=['path', 'Nom image'], inplace=True)\n",
    "    # écrire dans le csv immédiatement chaque batch\n",
    "    embeddings_df_batch.to_csv(\"final_image_train_embeddings.csv\", mode='a', header=not os.path.exists(\"final_image_train_embeddings.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
